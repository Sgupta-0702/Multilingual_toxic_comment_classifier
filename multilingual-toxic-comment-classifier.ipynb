{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":19018,"databundleVersionId":2703900,"sourceType":"competition"}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib as plt\nimport seaborn as sns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train-processed-seqlen128.csv\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check for missing data\nmissing_data = df.isnull().sum()\nprint(\"Missing Data:\\n\", missing_data)\n\nif missing_data.sum() == 0:\n    print(\"No missing data in the dataset.\")\nelse:\n    print(\"There is missing data in the dataset.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate message lengths based on the comment_text column\ndf['message_length'] = df['comment_text'].str.len()\n\n# Plot message length vs. frequency\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 6))\nplt.hist(df['message_length'], bins=60, color='green', alpha=0.7, label='All Comments')\nplt.xlabel('Message Length')\nplt.ylabel('Frequency')\nplt.title('Message Length for Training Data')\nplt.legend()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Calculate message lengths\ndf['message_length'] = df['comment_text'].str.len()\n\n# Determine if a comment is dirty or clean\ndf['is_dirty'] = df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1) > 0\n\n# Separate clean and dirty comments\nclean_comments = df[df['is_dirty'] == False]['message_length']\ndirty_comments = df[df['is_dirty'] == True]['message_length']\n\n# Plot message length vs. frequency for clean and dirty comments\nplt.figure(figsize=(12, 6))\nplt.hist(clean_comments, bins=100, color='blue', alpha=0.5, label='Clean Comments')\nplt.hist(dirty_comments, bins=100, color='red', alpha=0.5, label='Dirty Comments')\nplt.xlabel('Message Length')\nplt.ylabel('Frequency')\nplt.title('Message Length Distribution: Clean vs Dirty Comments')\nplt.legend()\nplt.xticks(ticks=range(0, 2000, 500))  # Adjusting x-axis ticks for better scaling\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Calculate the number of occurrences for each tag\ntag_counts = {\n    'toxic': df['toxic'].sum(),\n    'severe_toxic': df['severe_toxic'].sum(),\n    'obscene': df['obscene'].sum(),\n    'threat': df['threat'].sum(),\n    'insult': df['insult'].sum(),\n    'identity_hate': df['identity_hate'].sum(),\n    'clean': (df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1) == 0).sum()\n}\n\n# Convert the dictionary into a DataFrame for easy plotting\ntag_counts_df = pd.DataFrame(list(tag_counts.items()), columns=['Type', 'Occurrences'])\n\n# Plot the bar chart\nplt.figure(figsize=(10, 6))\nplt.bar(tag_counts_df['Type'], tag_counts_df['Occurrences'], color=['blue', 'orange', 'green', 'red', 'purple', 'brown', 'pink'])\nplt.xlabel('Type')\nplt.ylabel('Occurrences')\nplt.title('Number of Tags')\n# Annotating the bar values\nfor i, val in enumerate(tag_counts_df['Occurrences']):\n    plt.text(i, val + 1000, f'{val:.1f}', ha='center', fontsize=10)\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tag_columns = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\ndf['num_tags'] = df[tag_columns].sum(axis=1)\n\n# Count occurrences of each number of tags\ntag_counts = df['num_tags'].value_counts().sort_index()\n\n# Plot the bar chart\nplt.figure(figsize=(10, 6))\nbar_colors = plt.cm.tab20(range(len(tag_counts)))  # Optional: Colorful bars\ntag_counts.plot(kind='bar', color=bar_colors)\nplt.title('Number of Multiple Tags per Comment')\nplt.xlabel('Number of Tags')\nplt.ylabel('Occurrences')\n\n# Annotate bar plot with numbers\nfor index, value in enumerate(tag_counts):\n    plt.text(index, value + 500, str(value), ha='center', va='bottom', fontsize=10)\n\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to calculate the percentage of unique words in a comment\ndef percent_unique_words(text):\n    words = text.split()  # Split comment into words\n    if len(words) == 0:\n        return 0\n    unique_words = set(words)\n    return len(unique_words) / len(words) * 100\n\n# Add a new column for the percentage of unique words\ndf[\"percent_unique_words\"] = df[\"comment_text\"].apply(percent_unique_words)\n\n# Split the data into dirty and clean based on the label\ndirty_comments = df[df['is_dirty'] == 1][\"percent_unique_words\"]\nclean_comments = df[df['is_dirty'] == 0][\"percent_unique_words\"]\n\n# Plot the distributions using seaborn\nplt.figure(figsize=(10, 6))\nsns.kdeplot(dirty_comments, fill=True, color=\"red\", label=\"Dirty\")\nsns.kdeplot(clean_comments, fill=True, color=\"blue\", label=\"Clean\")\n\n# Add titles and labels\nplt.title(\"Percentage of Unique Words of Total Words in Comments\", fontsize=14)\nplt.xlabel(\"Percent Unique Words\", fontsize=12)\nplt.ylabel(\"Number of Occurrences\", fontsize=12)\nplt.legend()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df[\"percent_unique_words\"]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\ndef remove_ip_addresses(text):\n    if isinstance(text, str):\n        return re.sub(r'\\b(?:\\d{1,3}\\.){3}\\d{1,3}\\b', '', text)\n    return text\n\ndf['comment_text'] = df['comment_text'].apply(remove_ip_addresses)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install langid","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import langid\n\n\n# # Function to detect language\n# def detect_language(text):\n#     try:\n#         return langid.classify(text)[0]\n#     except Exception:\n#         return 'unknown'\n\n# # Apply language detection to the comment_text column\n# df['detected_lang'] = df['comment_text'].apply(detect_language)\n\n# # Display the dataset with detected languages\n# print(df.head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_validation = pd.read_csv(\"/kaggle/input/jigsaw-multilingual-toxic-comment-classification/validation.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_validation.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train_unprocessed=pd.read_csv(\"/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train_unprocessed.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}